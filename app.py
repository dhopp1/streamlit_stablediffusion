import streamlit as stimport hmacimport pandas as pdimport torchimport sysimport gcfrom datetime import datetime, timedeltaimport timeimport osfrom streamlit_server_state import server_state, server_state_lockfrom helper.txt2img import initialize_txt2img, gen_txt2imgfrom helper.img2img import initialize_img2img, gen_img2imgfrom helper.outpainting import initialize_outpainting, gen_outpainting### session initialization/login# last used timeif os.path.exists("metadata/last_used.txt") and "last_used" not in st.session_state:    file = open("metadata/last_used.txt", "r")    st.session_state["last_used"] = datetime.strptime(file.read(), '%Y-%m-%d %H:%M:%S.%f')    file.close()else:    st.session_state["last_used"] = datetime.now() - timedelta(hours=0, minutes=10)# last userif os.path.exists("metadata/user.txt"):    file = open("metadata/user.txt", "r")    st.session_state["last_user"] = file.read()    file.close()else:    st.session_state["last_user"] = "none"if "users_list" not in st.session_state:    st.session_state["users_list"] = pd.read_csv("metadata/user_list.csv")# passworddef check_password():    """Returns `True` if the user had the correct password."""    st.session_state["available"] = (datetime.now() - st.session_state["last_used"]).total_seconds() > 1 # available if last use more than 3 minutes ago            if not(st.session_state["available"]):        st.error(f"""Application in use by [{st.session_state['last_user']}](mailto:{st.session_state["users_list"].loc[lambda x: x.user == st.session_state['last_user'], 'email'].values[0]}). Refresh in 3 minutes, if they have stopped using it you will be able to log in.""")    def password_entered():        """Checks whether a password entered by the user is correct."""        if hmac.compare_digest(st.session_state["password"], st.secrets["password"]):            st.session_state["password_correct"] = True            del st.session_state["password"]  # Don't store the password.        else:            st.session_state["password_correct"] = False    # Return True if the password is validated.    if st.session_state.get("password_correct", False):        if st.session_state["available"]:            return True        # show input for user name    st.session_state["user_name"] = st.selectbox(       "User",       st.session_state["users_list"],       index=None,       placeholder="Select user...",    )    # Show input for password.    st.text_input(        "Password", type="password", on_change=password_entered, key="password"    )    if "password_correct" in st.session_state:        st.error("Password incorrect")    return Falseif not check_password():    st.stop()  # Do not continue if check_password is not True.    ###  app setup# headerst.title("Local Stable Diffusion")# Ddo not continue if a new user has booted off this oneif st.session_state["user_name"] != st.session_state["last_user"] and "user_recorded" in st.session_state:    if "model" in st.session_state:        st.session_state["model"].close_connection()        del st.session_state["model"].llm        del st.session_state["model"]        gc.collect()    st.error(f"""[{st.session_state['last_user']}](mailto:{st.session_state["users_list"].loc[lambda x: x.user == st.session_state['last_user'], 'email'].values[0]}) has logged on. Refresh in 3 minutes, if they have stopped using it you will be able to log in.""")    st.stop()    # record the userif "user_recorded" not in st.session_state:    f = open("metadata/user.txt", "w")    f.write(st.session_state["user_name"])    f.close()    st.session_state["user_recorded"] = True    server_state["user_name"] = st.session_state["user_name"]print(f'New user: {server_state["user_name"]}')    # record last interactionf = open("metadata/last_used.txt", "w")f.write(str(datetime.now()))f.close()# styles sheetswith open( "styles/style.css" ) as css:    st.markdown( f'<style>{css.read()}</style>' , unsafe_allow_html= True)    user_avatar = "https://www.svgrepo.com/show/524211/user.svg"#"\N{grinning face}"assistant_avatar = "https://www.svgrepo.com/show/375527/ai-platform.svg"#"\N{Robot Face}"### chat setup# initialize chat historyif "messages" not in st.session_state:    st.session_state.messages = []    # Display chat messages from history on app rerunfor message in st.session_state.messages:    avatar = user_avatar if message["role"] == "user" else assistant_avatar    with st.chat_message(message["role"], avatar=avatar):        if type(message["content"]) == dict:            st.image(message["content"]["image_path"], caption=message["content"]["caption"], output_format="PNG")        else:            st.markdown(message["content"])### directory and model setupif not(os.path.isdir("metadata/models/")):    os.mkdir("metadata/models/")    if not(os.path.isdir("metadata/input_images/")):    os.mkdir("metadata/input_images/")    if not(os.path.isdir("metadata/output_images/")):    os.mkdir("metadata/output_images/")    model_list = pd.read_csv("metadata/model_list.csv")# xlif os.path.isdir(model_list.loc[0, "path"]):    model_name = model_list.loc[0, "path"]else:    model_name = model_list.loc[0, "url"]# outpaintingif os.path.isdir(model_list.loc[1, "path"]):    outpainting_name = model_list.loc[1, "path"]else:    outpainting_name = model_list.loc[1, "url"]    # parametersif torch.cuda.is_available():    device = "cuda"elif torch.backends.mps.is_available() and torch.backends.mps.is_built():    device = "mps"else:    device = "cpu"torch_dtype = torch.float16 if device in ["cuda", "mps"] else Nonenum_variations = 1num_inference_steps = 20guidance_scale = 7.5height = 512width = 512manual_seeds = Nonenegative_prompt = "out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature."strength = 0.5outpainting = False### accept user inputif prompt := st.chat_input('Prompt...'):    # Display user message in chat message container    with st.chat_message("user", avatar=user_avatar):        st.markdown(prompt)    # Add user message to chat history    st.session_state.messages.append({"role": "user", "content": prompt})        # record last interaction    f = open("metadata/last_used.txt", "w")    f.write(str(datetime.now()))    f.close()        # clear the models    if st.session_state.messages[-1]["content"].lower() == "clear":        if 'txt2img_pipe' in globals():            del txt2img_pipe            gc.collect()                    if 'img2img_pipe' in globals():            del img2img_pipe            gc.collect()                    if 'outpainting_pipe' in globals():            del outpainting_pipe            gc.collect()                    if device == "cuda":            torch.cuda.empty_cache()    # txt2img    else:        if 'img2img_pipe' in globals():            del img2img_pipe            gc.collect()                            if 'outpainting_pipe' in globals():            del outpainting_pipe            gc.collect()                    if 'txt2img_pipe' not in globals():            with st.spinner('Loading model...'):                txt2img_pipe = initialize_txt2img(                    model_name, model_list.loc[0, "path"], device, torch_dtype                )                        with st.spinner('Generating...'):            img_paths = gen_txt2img(                pipe=txt2img_pipe,                prompt=st.session_state.messages[-1]["content"],                device=device,                num_variations=1,                num_inference_steps=num_inference_steps,                guidance_scale=guidance_scale,                height=height,                width=width,                manual_seeds=None,                negative_prompt=negative_prompt,            )        for img_path in img_paths:            with st.chat_message("assistant", avatar=assistant_avatar):                st.image(img_path, caption=f"{img_path.split('/')[-1].split('_')[0]}", output_format="PNG")            st.session_state.messages.append({"role": "assistant", "content": {"image_path": img_path, "caption": f"{img_path.split('/')[-1].split('_')[0]}"}})